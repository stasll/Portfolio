# Отчёт о проекте Data Science: Оптимизация потребления электроэнергии на этапе обработки стали

Этот файл содержит информацию о выполняемом проекте, в данном случае об оптимизации потребления электроэнергии с использованием моделей машинного обучения.

## Понимание бизнеса

### Определение проблемы
Нашей основной целью является оптимизация производственных расходов для металлургического комбината.

Нам необходимо создать модель машинного обучения, которая смогла бы предсказывать оптимальную температуру плавления сырья, избегая лишнего нагрева. Таким образом, конечным результатом нашей работы должна стать модель регрессии.

Набор данных нам был предоставлен работодателем. Он содержит данные о разных этапах обработки стали.

### Область применения
 - Задачей является построение и обучение модели регрессии, которая смогла бы предсказывать конечную температуру.
 - Мы проводим анализ в тетради Jupyter Notebook версии 6.5.4.

### План
1. **Провести исследовательский анализ:** Познакомиться с данными, понять как устроены таблицы, найти закономерности, связи, инсайты.
2. **Предобработка данных:** Собрать единую таблицу, в которую войдут данные, почищенные от пропущенных значений, выбросов и неважных для нас признаков. Из тренировочной выборки мы удалим *выбросы, аномальные мощности и низкую температуру*.
3. **Обучение моделей:** Выбрать оптимальные модели для задачи регрессии. Подобрав оптимальные гиперпараметры, обучить разные модели на этих данных. 
4. **Общий вывод:** Проверить, удалось ли достичь поставленных задач. Оставить рекомендации и советы для улучшения и оптимизации процесса обработки стали

### Показатели
Модель машинного обучения будет оцениваться на тестовом наборе, который будет составлять 25% от всех, пригодных для обучения, данных. Успешность модели может быть подтверждена метрикой MAE, которая должна быть ниже показателя в 6.8 градусов на тестовой выборке.

## Сбор и понимание данных
### Исходные данные
Исходные данные были предоставлены нам в виде 7 таблиц, включающих в себя разные этапы обработки стали:
- `data_arc_new.csv` — данные об электродах;
- `data_bulk_new.csv` — данные о подаче сыпучих материалов (объём);
- `data_bulk_time_new.csv` *—* данные о подаче сыпучих материалов (время);
- `data_gas_new.csv` — данные о продувке сплава газом];
- `data_temp_new.csv` — результаты измерения температуры];
- `data_wire_new.csv` — данные о проволочных материалах (объём);
- `data_wire_time_new.csv` — данные о проволочных материалах (время).

### Предобработка данных
Мы привели названия столбцов к удобному формату ('Активная мощность' - 'active power', 'Газ 1' - 'gas' и т.д.). 

Также, мы избавились от аномалий, удалив целиком партии с выбросами:
- Отрицательное значение мощности в данных о мощности.
- Температуры, ниже 1500 градусов(температура плавления).
- В данных о сыпучих смесях и проволочных данных удалили признаки, содержащие по одному значению
- В тренировочной выборке мы удалили выбросы в признаке 'Bulk 12', которые превышали значение 800.
    
Активную и реактивную мощность аггрегировали. Числа в этих признаках являются соответственно средними значениями и суммами мощностей по партии, а так же общей суммой этих мощностей.

В тестовую выборку мы поместили признак с первым замером температуры в партии, т.к. это является своего рода точкой отчёта в обработке стали.

Создали целевой признак, который содержит значение последнего замера температуры в партии и выяснили, что на последних 738 итерациях замеры отсутствуют.

Собрали датафрейм со всей информацией, необходимой для обучения модели. Мы ограничили датафрейм 2499 партиями, т.к. в остальные не содержали в себе целевого признака. Конечный датафрейм содержит в себе 2324 строки и 30 столбцов (включая целевой признак).

Мы поделили датафрейм на обучающую и тестовую выборку. В test_train_split аргумент 'random_state' равен **240423**.

### Обучение моделей
Мы создали три модели машинного обучения:
1. Модель регрессии `Случайного леса`
2. Модель регрессии `Lasso`
3. Модель градиентного бустинга `CatBoostRegressor`

### Оценка моделей
Для первых двух моделей мы использовали автоматический подбор гиперпараметров *GridSearchCV*, а в `CatBoostRegressor` мы использовали уже содержащийся в CatBoost метод *grid_search*.

Модели оценивались по метрике **Средней абсолютной ошибки (MAE)**. Модели `Случайного леса` и `Lasso` на обучающей выборке обе не достигли минимального порога 6.8: `Случайный лес` смог предсказывать с MAE = 7.082, а `Lasso` с MAE = 7.114.

Но модель градиентного бустинга `CatBoostRegressor` на обучающей выборке показала результат 6.194. А на тестовой метрика MAE составила ***6.49***.

Важность признаков CatBoostRegressor приводится ниже.

![2023-06-22_18-48-54.png](attachment:2023-06-22_18-48-54.png)
